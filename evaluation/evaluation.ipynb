{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3d504d",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01272913",
   "metadata": {},
   "source": [
    "## 1. BERT Base Raw Data\n",
    "\n",
    "### 1.1 Classification Report\n",
    "\n",
    "```txt\n",
    "======================================================================\n",
    "EVALUATION REPORTS FOR ALL SENTIMENT ANALYSIS MODELS\n",
    "======================================================================\n",
    "\n",
    "climate_data_raw Model Evaluation:\n",
    "----------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        news       0.63      0.62      0.62      1543\n",
    "         pro       0.87      0.81      0.84      4593\n",
    "     neutral       0.78      0.90      0.84      1855\n",
    "        anti       0.69      0.75      0.72       798\n",
    "\n",
    "    accuracy                           0.79      8789\n",
    "   macro avg       0.74      0.77      0.75      8789\n",
    "weighted avg       0.79      0.79      0.79      8789\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a6e9c",
   "metadata": {},
   "source": [
    "### 1.2 Training Performance\n",
    "\n",
    "<img src=\"../images/loss_curves_with_best_epoch_raw.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1efde8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Load all AUC data\n",
    "def load_all_auc_data():\n",
    "    auc_files = glob.glob('results/*_auc.json')\n",
    "    all_data = {}\n",
    "    \n",
    "    for file_path in auc_files:\n",
    "        model_type = file_path.split('/')[-1].replace('_auc.json', '')\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Extract the first model's data (assuming one model per file)\n",
    "        for model_name, auc_info in data.items():\n",
    "            all_data[model_type] = auc_info\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# Plot consolidated ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "all_auc_data = load_all_auc_data()\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "\n",
    "for i, (model_name, auc_info) in enumerate(all_auc_data.items()):\n",
    "    plt.plot(auc_info['fpr'], auc_info['tpr'],\n",
    "             label=f'{model_name} (AUC = {auc_info[\"auc\"]:.4f})',\n",
    "             color=colors[i], linewidth=2)\n",
    "\n",
    "# Plot diagonal line\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - All BERT Models Comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('consolidated_roc_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
